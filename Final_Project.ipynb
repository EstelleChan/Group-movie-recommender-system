{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Group code block completed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Group():\n",
    "    def __init__(self, config, members, candidate_items, ratings):\n",
    "        #member ids\n",
    "        self.members = sorted(members)\n",
    "        \n",
    "        #list of items that can be recommended. These should not have been\n",
    "        #watched by any member of group\n",
    "        self.candidate_items = candidate_items\n",
    "        self.actual_recos = []\n",
    "        self.false_positive = []\n",
    "        \n",
    "        self.ratings_per_member = [np.size(ratings[member].nonzero()) for member in self.members]\n",
    "        \n",
    "        #AF\n",
    "        self.grp_factors_af = []\n",
    "        self.bias_af = 0\n",
    "        #eval. metrics for AF method for this group\n",
    "        self.precision_af = 0\n",
    "        self.recall_af = 0\n",
    "        #recommended items acc. to AF method, \n",
    "        #after calculatng ratings of candidate items and filtering them\n",
    "        self.reco_list_af = [] \n",
    "        \n",
    "        #BF\n",
    "        self.grp_factors_bf = []\n",
    "        self.bias_bf = 0\n",
    "        self.precision_bf = 0\n",
    "        self.recall_bf = 0\n",
    "        self.reco_list_bf = []\n",
    "        \n",
    "        #WBF\n",
    "        self.grp_factors_wbf = []\n",
    "        self.bias_wbf = 0\n",
    "        self.precision_wbf = 0\n",
    "        self.recall_wbf = 0\n",
    "        #W matrix from the paper\n",
    "        self.weight_matrix_wbf = []\n",
    "        self.reco_list_wbf = []\n",
    "    \n",
    "    #verifies that given list of members can form a group w.r.t given data\n",
    "    #ensure that there is atleast 1 movie in training data that hasn't been \n",
    "    #watched by any member of the group. Only these can be recommended.\n",
    "    #call this method before calling group constructor.\n",
    "    # For eg.\n",
    "    @staticmethod\n",
    "    def find_candidate_items(ratings, members):\n",
    "        if len(members) == 0: return []\n",
    "        \n",
    "        unwatched_items = np.argwhere(ratings[members[0]] == 0)\n",
    "        for member in members:\n",
    "            cur_unwatched = np.argwhere(ratings[member] == 0)\n",
    "            unwatched_items = np.intersect1d(unwatched_items, cur_unwatched)\n",
    "        \n",
    "        return unwatched_items\n",
    "    \n",
    "    #programmatically generate groups of given size\n",
    "    @staticmethod\n",
    "    def generate_groups(cfg, ratings, test_ratings, num_users, count, size, disjoint = True):\n",
    "        avbl_users = [i for i in range(num_users)]\n",
    "        groups = []\n",
    "        testable_threshold = 50\n",
    "        \n",
    "        iter_idx = 0\n",
    "        while iter_idx in range(count):\n",
    "            group_members = np.random.choice(avbl_users, size = size, replace = False)\n",
    "            candidate_items = Group.find_candidate_items(ratings, group_members)\n",
    "            non_eval_items = Group.non_testable_items(group_members, test_ratings)\n",
    "            testable_items = np.setdiff1d(candidate_items, non_eval_items)\n",
    "            \n",
    "            if len(candidate_items) != 0 and len(testable_items) >= testable_threshold:\n",
    "                groups += [Group(cfg, group_members, candidate_items, ratings)]\n",
    "                avbl_users = np.setdiff1d(avbl_users, group_members)\n",
    "                iter_idx += 1\n",
    "                \n",
    "        return groups\n",
    "    \n",
    "    @staticmethod\n",
    "    def non_testable_items(members, ratings): \n",
    "        non_eval_items = np.argwhere(ratings[members[0]] == 0)\n",
    "        for member in members:\n",
    "            cur_non_eval_items = np.argwhere(ratings[member] == 0)\n",
    "            non_eval_items = np.intersect1d(non_eval_items, cur_non_eval_items)\n",
    "        return non_eval_items\n",
    "    \n",
    "    def generate_actual_recommendations(self, ratings, threshold):\n",
    "        non_eval_items = Group.non_testable_items(self.members, ratings)\n",
    "            \n",
    "        items = np.argwhere(np.logical_or(ratings[self.members[0]] >= threshold, ratings[self.members[0]] == 0)).flatten()\n",
    "        fp = np.argwhere(np.logical_and(ratings[self.members[0]] > 0, ratings[self.members[0]] < threshold)).flatten()\n",
    "        for member in self.members:\n",
    "            cur_items = np.argwhere(np.logical_or(ratings[member] >= threshold, ratings[member] == 0)).flatten()\n",
    "            fp = np.union1d(fp, np.argwhere(np.logical_and(ratings[member] > 0, ratings[member] < threshold)).flatten())\n",
    "            items = np.intersect1d(items, cur_items)\n",
    "        \n",
    "        items = np.setdiff1d(items, non_eval_items)\n",
    "\n",
    "        self.actual_recos = items\n",
    "#         print 'acutal reco list: ', self.actual_recos\n",
    "        self.false_positive = fp\n",
    "\n",
    "    def evaluate_af(self):\n",
    "        tp = float(np.intersect1d(self.actual_recos, self.reco_list_af).size)\n",
    "        print '\\ntp: ', tp\n",
    "        fp = float(np.intersect1d(self.false_positive, self.reco_list_af).size)\n",
    "        print 'fp: ', fp\n",
    "        \n",
    "        try:\n",
    "            self.precision_af = tp / (tp + fp)\n",
    "            print 'precision_af: ', self.precision_af\n",
    "        except ZeroDivisionError:\n",
    "            self.precision_af = np.NaN\n",
    "            print 'precision_af: ', self.precision_af\n",
    "            \n",
    "        try:\n",
    "            self.recall_af = tp / self.actual_recos.size\n",
    "        except ZeroDivisionError:\n",
    "            self.recall_af = np.NaN\n",
    "        print 'recall_af: ', self.recall_af\n",
    "        \n",
    "        return (self.precision_af, self.recall_af, tp, fp)\n",
    "\n",
    "        print \"\\nPrecision: \" + str(self.precision_af)\n",
    "        print \"Recall: \" + str(self.recall_af)\n",
    "\n",
    "    def evaluate_bf(self):\n",
    "        tp = float(np.intersect1d(self.actual_recos, self.reco_list_bf).size)\n",
    "        print '\\ntp: ', tp\n",
    "        fp = float(np.intersect1d(self.false_positive, self.reco_list_bf).size)\n",
    "        print 'fp: ', fp\n",
    "\n",
    "        try:\n",
    "            self.precision_bf = tp / (tp + fp)\n",
    "            print 'precision_bf: ', self.precision_bf\n",
    "        except ZeroDivisionError:\n",
    "            self.precision_bf = np.NaN\n",
    "            print 'precision_bf: ', self.precision_bf\n",
    "\n",
    "        try:\n",
    "            self.recall_bf = tp / self.actual_recos.size\n",
    "        except ZeroDivisionError:\n",
    "            self.recall_bf = np.NaN\n",
    "        print 'recall_bf: ', self.recall_bf\n",
    "\n",
    "        return (self.precision_bf, self.recall_bf, tp, fp)\n",
    "\n",
    "        print \"\\nPrecision: \" + str(self.precision_bf)\n",
    "        print \"Recall: \" + str(self.recall_bf)\n",
    "\n",
    "    def evaluate_wbf(self):\n",
    "        tp = float(np.intersect1d(self.actual_recos, self.reco_list_wbf).size)\n",
    "        print '\\ntp: ', tp\n",
    "        fp = float(np.intersect1d(self.false_positive, self.reco_list_wbf).size)\n",
    "        print 'fp: ', fp\n",
    "\n",
    "        try:\n",
    "            self.precision_wbf = tp / (tp + fp)\n",
    "            print 'precision_wbf: ', self.precision_wbf\n",
    "        except ZeroDivisionError:\n",
    "            self.precision_wbf = np.NaN\n",
    "            print 'precision_wbf: ', self.precision_wbf\n",
    "\n",
    "        try:\n",
    "            self.recall_wbf = tp / self.actual_recos.size\n",
    "        except ZeroDivisionError:\n",
    "            self.recall_wbf = np.NaN\n",
    "        print 'recall_wbf: ', self.recall_wbf\n",
    "\n",
    "        return (self.precision_wbf, self.recall_wbf, tp, fp)\n",
    "\n",
    "        print \"\\nPrecision: \" + str(self.precision_wbf)\n",
    "        print \"Recall: \" + str(self.recall_wbf)\n",
    "\n",
    "\n",
    "print 'Class Group code block completed!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregators block completed!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class Aggregators:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #pass ratings or factors as input\n",
    "    @staticmethod\n",
    "    def average(arr):\n",
    "        return np.average(arr, axis = 0, weights = None)\n",
    "\n",
    "    @staticmethod\n",
    "    def average_bf(arr):\n",
    "        arr[arr == 0] = np.nan\n",
    "        return np.nanmean(arr, axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def weighted_average(arr, weights):\n",
    "        return np.average(arr, axis = 0, weights = weights)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mode(arr):\n",
    "        pass\n",
    "        \n",
    "    @staticmethod\n",
    "    def median(arr):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def least_misery(self, arr):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def most_pleasure(self, arr):\n",
    "        pass\n",
    "print 'Aggregators block completed!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupRec block completed!\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# class Group():\n",
    "#     def __init__(self, config, members, candidate_items, ratings):\n",
    "#         #member ids\n",
    "#         self.members = sorted(members)\n",
    "        \n",
    "#         #list of items that can be recommended. These should not have been\n",
    "#         #watched by any member of group\n",
    "#         self.candidate_items = candidate_items\n",
    "#         self.actual_recos = []\n",
    "#         self.false_positive = []\n",
    "        \n",
    "#         self.ratings_per_member = [np.size(ratings[member].nonzero()) for member in self.members]\n",
    "        \n",
    "#         #AF\n",
    "#         self.grp_factors_af = []\n",
    "#         self.bias_af = 0\n",
    "#         #eval. metrics for AF method for this group\n",
    "#         self.precision_af = 0\n",
    "#         self.recall_af = 0\n",
    "#         #recommended items acc. to AF method, \n",
    "#         #after calculatng ratings of candidate items and filtering them\n",
    "#         self.reco_list_af = [] \n",
    "        \n",
    "#         #BF\n",
    "#         self.grp_factors_bf = []\n",
    "#         self.bias_bf = 0\n",
    "#         self.precision_bf = 0\n",
    "#         self.recall_bf = 0\n",
    "#         self.reco_list_bf = []\n",
    "        \n",
    "#         #WBF\n",
    "#         self.grp_factors_wbf = []\n",
    "#         self.bias_wbf = 0\n",
    "#         self.precision_wbf = 0\n",
    "#         self.recall_wbf = 0\n",
    "#         #W matrix from the paper\n",
    "#         self.weight_matrix_wbf = []\n",
    "#         self.reco_list_wbf = []\n",
    "    \n",
    "#     #verifies that given list of members can form a group w.r.t given data\n",
    "#     #ensure that there is atleast 1 movie in training data that hasn't been \n",
    "#     #watched by any member of the group. Only these can be recommended.\n",
    "#     #call this method before calling group constructor.\n",
    "#     # For eg.\n",
    "#     @staticmethod\n",
    "#     def find_candidate_items(ratings, members):\n",
    "#         if len(members) == 0: return []\n",
    "        \n",
    "#         unwatched_items = np.argwhere(ratings[members[0]] == 0)\n",
    "#         for member in members:\n",
    "#             cur_unwatched = np.argwhere(ratings[member] == 0)\n",
    "#             unwatched_items = np.intersect1d(unwatched_items, cur_unwatched)\n",
    "        \n",
    "#         return unwatched_items\n",
    "    \n",
    "#     #programmatically generate groups of given size\n",
    "#     @staticmethod\n",
    "#     def generate_groups(cfg, ratings, test_ratings, num_users, count, size, disjoint = True):\n",
    "#         avbl_users = [i for i in range(num_users)]\n",
    "#         groups = []\n",
    "#         testable_threshold = 50\n",
    "        \n",
    "#         iter_idx = 0\n",
    "#         while iter_idx in range(count):\n",
    "#             group_members = np.random.choice(avbl_users, size = size, replace = False)\n",
    "#             candidate_items = Group.find_candidate_items(ratings, group_members)\n",
    "#             non_eval_items = Group.non_testable_items(group_members, test_ratings)\n",
    "#             testable_items = np.setdiff1d(candidate_items, non_eval_items)\n",
    "            \n",
    "#             if len(candidate_items) != 0 and len(testable_items) >= testable_threshold:\n",
    "#                 groups += [Group(cfg, group_members, candidate_items, ratings)]\n",
    "#                 avbl_users = np.setdiff1d(avbl_users, group_members)\n",
    "#                 iter_idx += 1\n",
    "                \n",
    "#         return groups\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def non_testable_items(members, ratings): \n",
    "#         non_eval_items = np.argwhere(ratings[members[0]] == 0)\n",
    "#         for member in members:\n",
    "#             cur_non_eval_items = np.argwhere(ratings[member] == 0)\n",
    "#             non_eval_items = np.intersect1d(non_eval_items, cur_non_eval_items)\n",
    "#         return non_eval_items\n",
    "    \n",
    "#     def generate_actual_recommendations(self, ratings, threshold):\n",
    "#         non_eval_items = Group.non_testable_items(self.members, ratings)\n",
    "            \n",
    "#         items = np.argwhere(np.logical_or(ratings[self.members[0]] >= threshold, ratings[self.members[0]] == 0)).flatten()\n",
    "#         fp = np.argwhere(np.logical_and(ratings[self.members[0]] > 0, ratings[self.members[0]] < threshold)).flatten()\n",
    "#         for member in self.members:\n",
    "#             cur_items = np.argwhere(np.logical_or(ratings[member] >= threshold, ratings[member] == 0)).flatten()\n",
    "#             fp = np.union1d(fp, np.argwhere(np.logical_and(ratings[member] > 0, ratings[member] < threshold)).flatten())\n",
    "#             items = np.intersect1d(items, cur_items)\n",
    "        \n",
    "#         items = np.setdiff1d(items, non_eval_items)\n",
    "\n",
    "#         self.actual_recos = items\n",
    "# #         print 'acutal reco list: ', self.actual_recos\n",
    "#         self.false_positive = fp\n",
    "\n",
    "#     def evaluate_af(self):\n",
    "#         tp = float(np.intersect1d(self.actual_recos, self.reco_list_af).size)\n",
    "#         print '\\ntp: ', tp\n",
    "#         fp = float(np.intersect1d(self.false_positive, self.reco_list_af).size)\n",
    "#         print 'fp: ', fp\n",
    "        \n",
    "#         try:\n",
    "#             self.precision_af = tp / (tp + fp)\n",
    "#             print 'precision_af: ', self.precision_af\n",
    "#         except ZeroDivisionError:\n",
    "#             self.precision_af = np.NaN\n",
    "#             print 'precision_af: ', self.precision_af\n",
    "            \n",
    "#         try:\n",
    "#             self.recall_af = tp / self.actual_recos.size\n",
    "#         except ZeroDivisionError:\n",
    "#             self.recall_af = np.NaN\n",
    "#         print 'recall_af: ', self.recall_af\n",
    "        \n",
    "#         return (self.precision_af, self.recall_af, tp, fp)\n",
    "\n",
    "#         print \"\\nPrecision: \" + str(self.precision_af)\n",
    "#         print \"Recall: \" + str(self.recall_af)\n",
    "\n",
    "#     def evaluate_bf(self):\n",
    "#         tp = float(np.intersect1d(self.actual_recos, self.reco_list_bf).size)\n",
    "#         print '\\ntp: ', tp\n",
    "#         fp = float(np.intersect1d(self.false_positive, self.reco_list_bf).size)\n",
    "#         print 'fp: ', fp\n",
    "\n",
    "#         try:\n",
    "#             self.precision_bf = tp / (tp + fp)\n",
    "#             print 'precision_bf: ', self.precision_bf\n",
    "#         except ZeroDivisionError:\n",
    "#             self.precision_bf = np.NaN\n",
    "#             print 'precision_bf: ', self.precision_bf\n",
    "\n",
    "#         try:\n",
    "#             self.recall_bf = tp / self.actual_recos.size\n",
    "#         except ZeroDivisionError:\n",
    "#             self.recall_bf = np.NaN\n",
    "#         print 'recall_bf: ', self.recall_bf\n",
    "\n",
    "#         return (self.precision_bf, self.recall_bf, tp, fp)\n",
    "\n",
    "#         print \"\\nPrecision: \" + str(self.precision_bf)\n",
    "#         print \"Recall: \" + str(self.recall_bf)\n",
    "\n",
    "#     def evaluate_wbf(self):\n",
    "#         tp = float(np.intersect1d(self.actual_recos, self.reco_list_wbf).size)\n",
    "#         print '\\ntp: ', tp\n",
    "#         fp = float(np.intersect1d(self.false_positive, self.reco_list_wbf).size)\n",
    "#         print 'fp: ', fp\n",
    "\n",
    "#         try:\n",
    "#             self.precision_wbf = tp / (tp + fp)\n",
    "#             print 'precision_wbf: ', self.precision_wbf\n",
    "#         except ZeroDivisionError:\n",
    "#             self.precision_wbf = np.NaN\n",
    "#             print 'precision_wbf: ', self.precision_wbf\n",
    "\n",
    "#         try:\n",
    "#             self.recall_wbf = tp / self.actual_recos.size\n",
    "#         except ZeroDivisionError:\n",
    "#             self.recall_wbf = np.NaN\n",
    "#         print 'recall_wbf: ', self.recall_wbf\n",
    "\n",
    "#         return (self.precision_wbf, self.recall_wbf, tp, fp)\n",
    "\n",
    "#         print \"\\nPrecision: \" + str(self.precision_wbf)\n",
    "#         print \"Recall: \" + str(self.recall_wbf)\n",
    "\n",
    "\n",
    "# import math\n",
    "# import numpy as np\n",
    "\n",
    "# class Aggregators:\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "    \n",
    "#     #pass ratings or factors as input\n",
    "#     @staticmethod\n",
    "#     def average(arr):\n",
    "#         return np.average(arr, axis = 0, weights = None)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def average_bf(arr):\n",
    "#         arr[arr == 0] = np.nan\n",
    "#         return np.nanmean(arr, axis=0)\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def weighted_average(arr, weights):\n",
    "#         return np.average(arr, axis = 0, weights = weights)\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def mode(arr):\n",
    "#         pass\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def median(arr):\n",
    "#         pass\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def least_misery(self, arr):\n",
    "#         pass\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def most_pleasure(self, arr):\n",
    "#         pass\n",
    "    \n",
    "\n",
    "from Aggregators import Aggregators\n",
    "from Group import Group\n",
    "from Config import Config\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as ps\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#overflow warnings should be raised as errors\n",
    "np.seterr(over='raise')\n",
    "\n",
    "#global class.\n",
    "class GroupRec:\n",
    "    def __init__(self):\n",
    "        self.cfg = Config(r\"./config.conf\")\n",
    "        \n",
    "        #training and testing matrices, init. with random sizes\n",
    "        self.ratings = np.ndarray((10,10))\n",
    "        self.test_ratings = np.ndarray((10,10))\n",
    "        \n",
    "        #read data into above matrices\n",
    "        self.read_data(self.cfg.training_file)\n",
    "        \n",
    "        self.num_users = self.ratings.shape[0]\n",
    "        self.num_items = self.ratings.shape[1]\n",
    "        \n",
    "        #predicted ratings matrix based on factors. \n",
    "        self.predictions = np.zeros((self.num_users, self.num_items))\n",
    "        \n",
    "        #output after self.sgd_factorize()\n",
    "        #initialize all unknowns with random values from -1 to 1\n",
    "        self.user_factors = np.random.uniform(-1, 1, (self.ratings.shape[0], self.cfg.num_factors))\n",
    "        self.item_factors = np.random.uniform(-1, 1, (self.ratings.shape[1], self.cfg.num_factors))\n",
    "        \n",
    "        #either above or initialize factors with normally distributed numbers\n",
    "#         self.user_factors = np.random.normal(scale=1./self.cfg.num_factors, size = (self.num_users, self.cfg.num_factors))\n",
    "#         self.item_factors = np.random.normal(scale=1./self.cfg.num_factors, size = (self.num_items, self.cfg.num_factors))\n",
    "        \n",
    "        self.user_biases = np.zeros(self.num_users)\n",
    "        self.item_biases = np.zeros(self.num_items)\n",
    "        \n",
    "        #global mean of ratings a.k.a mu\n",
    "        self.ratings_global_mean = 0\n",
    "        pass\n",
    "\n",
    "    #add list of groups to grouprec\n",
    "    def add_groups(self, groups):\n",
    "        self.groups = groups\n",
    "        pass\n",
    "    \n",
    "    #remove groups\n",
    "    def remove_groups(self, groups):\n",
    "        self.groups = []\n",
    "        pass\n",
    "    \n",
    "    #read training and testing data into matrices\n",
    "    def read_data(self, file):\n",
    "        column_headers = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "        print 'Reading data from ', file, '...'\n",
    "        data = ps.read_csv(file, sep = '\\t', names = column_headers)\n",
    "        print 'Reading testing data from ', self.cfg.testing_file, '...'\n",
    "        testing_data = ps.read_csv(self.cfg.testing_file, sep = '\\t', names = column_headers)\n",
    "        \n",
    "        num_users = max(data.user_id.unique())\n",
    "        num_items = max(data.item_id.unique())\n",
    "        \n",
    "        self.ratings = np.zeros((num_users, num_items))\n",
    "        self.test_ratings = np.zeros((num_users, num_items))\n",
    "        \n",
    "        for row in data.itertuples(index = False):\n",
    "            self.ratings[row.user_id - 1, row.item_id - 1] = row.rating\n",
    "        \n",
    "        for row in testing_data.itertuples(index = False):\n",
    "            self.test_ratings[row.user_id - 1, row.item_id - 1] = row.rating \n",
    "        \n",
    "    #split data set file into training and test file by ratio \n",
    "    def split_data(self, data_file, training_ratio = 0.7):\n",
    "        pass\n",
    "    \n",
    "    def predict_user_rating(self, user, item):\n",
    "        prediction = self.ratings_global_mean + self.user_biases[user] + self.item_biases[item]\n",
    "        prediction += self.user_factors[user, :].dot(self.item_factors[item, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    def predict_group_rating(self, group, item, method):\n",
    "        #bias_grp and\n",
    "        if (method == 'af'):\n",
    "            factors = group.grp_factors_af; bias_group = group.bias_af\n",
    "        elif (method == 'bf'):\n",
    "            factors = group.grp_factors_bf; bias_group = group.bias_bf\n",
    "        elif (method == 'wbf'):\n",
    "            factors = group.grp_factors_wbf; bias_group = group.bias_wbf\n",
    "        \n",
    "        return self.ratings_global_mean + bias_group + self.item_biases[item] \\\n",
    "                                        + np.dot(factors.T, self.item_factors[item])\n",
    "        \n",
    "    #matrix factorization code, this should be run before af, bf or wbf\n",
    "    #outputs from this are used in methods\n",
    "    def sgd_factorize(self):\n",
    "        #solve for these for matrix ratings        \n",
    "        ratings_row, ratings_col = self.ratings.nonzero()\n",
    "        num_ratings = len(ratings_row)\n",
    "        learning_rate = self.cfg.learning_rate_mf\n",
    "        regularization = self.cfg.lambda_mf\n",
    "        \n",
    "        self.ratings_global_mean = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "        \n",
    "        print 'Doing matrix factorization...'\n",
    "        try:\n",
    "            for iter in range(self.cfg.max_iterations_mf):\n",
    "                print 'Iteration: ', iter\n",
    "                rating_indices = np.arange(num_ratings)\n",
    "                np.random.shuffle(rating_indices)\n",
    "                \n",
    "                for idx in rating_indices:\n",
    "                    user = ratings_row[idx]\n",
    "                    item = ratings_col[idx]\n",
    "\n",
    "                    pred = self.predict_user_rating(user, item)\n",
    "                    error = self.ratings[user][item] - pred\n",
    "                    \n",
    "                    self.user_factors[user] += learning_rate \\\n",
    "                                                * ((error * self.item_factors[item]) - (regularization * self.user_factors[user]))\n",
    "                    self.item_factors[item] += learning_rate \\\n",
    "                                                * ((error * self.user_factors[user]) - (regularization * self.item_factors[item]))\n",
    "                    \n",
    "                    self.user_biases[user] += learning_rate * (error - regularization * self.user_biases[user])\n",
    "                    self.item_biases[item] += learning_rate * (error - regularization * self.item_biases[item])\n",
    "            \n",
    "                self.sgd_mse()\n",
    "            \n",
    "        except FloatingPointError:\n",
    "            print 'Floating point Error: '\n",
    "            \n",
    "    def predict_all_ratings(self):\n",
    "        for user in range(self.num_users):\n",
    "            for item in range(self.num_items):\n",
    "                self.predictions[user, item] = self.predict_user_rating(user, item)\n",
    "        \n",
    "    \n",
    "    def sgd_mse(self):\n",
    "        self.predict_all_ratings()\n",
    "        predicted_training_ratings = self.predictions[self.ratings.nonzero()].flatten()\n",
    "        actual_training_ratings = self.ratings[self.ratings.nonzero()].flatten()\n",
    "        \n",
    "        predicted_test_ratings = self.predictions[self.test_ratings.nonzero()].flatten()\n",
    "        actual_test_ratings = self.test_ratings[self.test_ratings.nonzero()].flatten()\n",
    "    \n",
    "        training_mse = mean_squared_error(predicted_training_ratings, actual_training_ratings)\n",
    "        print 'training mse: ', training_mse\n",
    "        test_mse = mean_squared_error(predicted_test_ratings, actual_test_ratings)\n",
    "        print 'test mse: ', test_mse\n",
    "            \n",
    "        \n",
    "    #AF method\n",
    "    # Check if we want this method to take multiple groups or single group\n",
    "    # as input\n",
    "    def af_runner(self, groups = None, aggregator = Aggregators.average):\n",
    "        #if groups is not passed, use self.groups\n",
    "        if (groups is None):\n",
    "            groups = self.groups\n",
    "        \n",
    "        #calculate factors\n",
    "        for group in groups:\n",
    "            member_factors = self.user_factors[group.members, :]\n",
    "            member_biases = self.user_biases[group.members]\n",
    "        \n",
    "            #aggregate the factors\n",
    "            if (aggregator == Aggregators.average):\n",
    "                group.grp_factors_af = aggregator(member_factors)\n",
    "                group.bias_af = aggregator(member_biases)\n",
    "            elif (aggregator == Aggregators.weighted_average):\n",
    "                group.grp_factors_af = aggregator(member_factors, weights = group.ratings_per_member)\n",
    "                group.bias_af = aggregator(member_biases, weights = group.ratings_per_member)\n",
    "            \n",
    "            #predict ratings for all candidate items\n",
    "            group_candidate_ratings = {}\n",
    "            for idx, item in enumerate(group.candidate_items):\n",
    "                cur_rating = self.predict_group_rating(group, item, 'af')\n",
    "                \n",
    "                if (cur_rating > self.cfg.rating_threshold_af):\n",
    "                    group_candidate_ratings[item] = cur_rating\n",
    "            \n",
    "            #sort and filter to keep top 'num_recos_af' recommendations\n",
    "            group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[:self.cfg.num_recos_af]\n",
    "            \n",
    "            group.reco_list_af = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "#             print 'members: ', group.members\n",
    "#             print 'recommended items: ', group.reco_list_af\n",
    "#             print 'recommended item ratings: ', group_candidate_ratings \n",
    "\n",
    "    def bf_runner(self, groups=None, aggregator=Aggregators.average_bf):\n",
    "        # aggregate user ratings into virtual group\n",
    "        # calculate factors of group\n",
    "        lamb = self.cfg.lambda_mf\n",
    "\n",
    "        for group in groups:\n",
    "            all_movies = np.arange(len(self.ratings.T))\n",
    "            watched_items = sorted(list(set(all_movies) - set(group.candidate_items)))\n",
    "\n",
    "            group_rating = self.ratings[group.members, :]\n",
    "            agg_rating = aggregator(group_rating)\n",
    "            s_g = []\n",
    "            for j in watched_items:\n",
    "                s_g.append(agg_rating[j] - self.ratings_global_mean - self.item_biases[j])\n",
    "\n",
    "            # creating matrix A : contains rows of [item_factors of items in watched_list + '1' vector]\n",
    "            A = np.zeros((0, self.cfg.num_factors))\n",
    "\n",
    "            for item in watched_items:\n",
    "                A = np.vstack([A, self.item_factors[item]])\n",
    "            v = np.ones((len(watched_items), 1))\n",
    "            A = np.c_[A, v]\n",
    "\n",
    "            factor_n_bias = np.dot(np.linalg.inv(np.dot(A.T, A) + lamb * np.identity(self.cfg.num_factors + 1)), np.dot(A.T, s_g))\n",
    "            group.grp_factors_bf = factor_n_bias[:-1]\n",
    "            group.bias_bf = factor_n_bias[-1]\n",
    "\n",
    "            # Making recommendations on candidate list :\n",
    "            group_candidate_ratings = {}\n",
    "            for idx, item in enumerate(group.candidate_items):\n",
    "                cur_rating = self.predict_group_rating(group, item, 'bf')\n",
    "\n",
    "                if (cur_rating > self.cfg.rating_threshold_bf):\n",
    "                    group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "            # sort and filter to keep top 'num_recos_bf' recommendations\n",
    "            group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[\n",
    "                                      :self.cfg.num_recos_bf]\n",
    "\n",
    "            group.reco_list_bf = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "            #             print 'members: ', group.members\n",
    "            #             print 'recommended items: ', group.reco_list_bf\n",
    "            #             print 'recommended item ratings: ', group_candidate_ratings\n",
    "\n",
    "\n",
    "    def wbf_runner(self, groups=None, aggregator=Aggregators.average_bf):\n",
    "        # aggregate user ratings into virtual group\n",
    "        # calculate factors of group\n",
    "        lamb = self.cfg.lambda_mf\n",
    "        for group in groups:\n",
    "            all_movies = np.arange(len(self.ratings.T))\n",
    "            watched_items = sorted(list(set(all_movies) - set(group.candidate_items)))\n",
    "\n",
    "            group_rating = self.ratings[group.members, :]\n",
    "            agg_rating = aggregator(group_rating)\n",
    "            s_g = []\n",
    "            for j in watched_items:\n",
    "                s_g.append(agg_rating[j] - self.ratings_global_mean - self.item_biases[j])\n",
    "\n",
    "            # creating matrix A : contains rows of [item_factors of items in watched_list + '1' vector]\n",
    "            A = np.zeros((0, self.cfg.num_factors))  # 3 is the number of features here = K\n",
    "\n",
    "            for item in watched_items:\n",
    "                A = np.vstack([A, self.item_factors[item]])\n",
    "            v = np.ones((len(watched_items), 1))\n",
    "            A = np.c_[A, v]\n",
    "\n",
    "            wt = []\n",
    "            for item in watched_items:\n",
    "                rated = np.argwhere(self.ratings[:, item] != 0)  # list of users who have rated this movie\n",
    "                watched = np.intersect1d(rated, group)  # list of group members who have watched this movie\n",
    "                std_dev = np.std(filter(lambda a: a != 0, self.ratings[:, item]))  # std deviation for the rating of the item\n",
    "                wt += [len(watched) / float(len(group.members)) * 1 / (1 + std_dev)]  # list containing diagonal elements\n",
    "            W = np.diag(wt)  # diagonal weight matrix\n",
    "\n",
    "            factor_n_bias = np.dot(np.linalg.inv(np.dot(np.dot(A.T, W),A) + lamb * np.identity(self.cfg.num_factors + 1)),\n",
    "                                   np.dot(np.dot(A.T, W), s_g))\n",
    "            group.grp_factors_wbf = factor_n_bias[:-1]\n",
    "            group.bias_wbf = factor_n_bias[-1]\n",
    "\n",
    "            # Making recommendations on candidate list :\n",
    "            group_candidate_ratings = {}\n",
    "            for idx, item in enumerate(group.candidate_items):\n",
    "                cur_rating = self.predict_group_rating(group, item, 'wbf')\n",
    "\n",
    "                if (cur_rating > self.cfg.rating_threshold_wbf):\n",
    "                    group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "            # sort and filter to keep top 'num_recos_wbf' recommendations\n",
    "            group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[\n",
    "                                      :self.cfg.num_recos_wbf]\n",
    "\n",
    "            group.reco_list_wbf = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "            #             print 'members: ', group.members\n",
    "            #             print 'recommended items: ', group.reco_list_wbf\n",
    "            #             print 'recommended item ratings: ', group_candidate_ratings\n",
    "\n",
    "        pass\n",
    "\n",
    "    def evaluation(self):\n",
    "#         self.read_data(self.cfg.testing_file, False)\n",
    "\n",
    "        # For AF\n",
    "        af_precision_list = []\n",
    "        af_recall_list = []\n",
    "        af_mean_precision = 0\n",
    "        print \"#########-------For AF-------#########\"\n",
    "        for grp in self.groups:\n",
    "            grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_af)\n",
    "            (precision, recall, tp, fp) = grp.evaluate_af()\n",
    "            af_precision_list.append(precision)\n",
    "            af_recall_list.append(recall)\n",
    "        \n",
    "        af_mean_precision = np.nanmean(np.array(af_precision_list))\n",
    "        af_mean_recall = np.nanmean(np.array(af_recall_list))\n",
    "        print '\\nAF method: mean precision: ', af_mean_precision\n",
    "        print 'AF method: mean recall: ', af_mean_recall\n",
    "\n",
    "        #For BF\n",
    "        bf_precision_list = []\n",
    "        bf_recall_list = []\n",
    "        bf_mean_precision = 0\n",
    "        print \"#########-------For BF-------#########\"\n",
    "        for grp in self.groups:\n",
    "            grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_bf)\n",
    "            (precision, recall, tp, fp) = grp.evaluate_bf()\n",
    "            bf_precision_list.append(precision)\n",
    "            bf_recall_list.append(recall)\n",
    "\n",
    "        bf_mean_precision = np.nanmean(np.array(bf_precision_list))\n",
    "        bf_mean_recall = np.nanmean(np.array(bf_recall_list))\n",
    "        print '\\nBF method: mean precision: ', bf_mean_precision\n",
    "        print 'BF method: mean recall: ', bf_mean_recall\n",
    "\n",
    "        #For BF\n",
    "        wbf_precision_list = []\n",
    "        wbf_recall_list = []\n",
    "        wbf_mean_precision = 0\n",
    "        print \"#########-------For WBF-------#########\"\n",
    "        for grp in self.groups:\n",
    "            grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_wbf)\n",
    "            (precision, recall, tp, fp) = grp.evaluate_wbf()\n",
    "            wbf_precision_list.append(precision)\n",
    "            wbf_recall_list.append(recall)\n",
    "\n",
    "        wbf_mean_precision = np.nanmean(np.array(wbf_precision_list))\n",
    "        wbf_mean_recall = np.nanmean(np.array(wbf_recall_list))\n",
    "        print '\\nWBF method: mean precision: ', wbf_mean_precision\n",
    "        print 'WBF method: mean recall: ', wbf_mean_recall\n",
    "\n",
    "        # # For BF\n",
    "        # for grp in self.groups:\n",
    "        #     grp.generate_actual_recommendations(self.ratings, self.cfg.rating_threshold_bf)\n",
    "        #     grp.evaluate_bf()\n",
    "        #\n",
    "        # # For WBF\n",
    "        # for grp in self.groups:\n",
    "        #     grp.generate_actual_recommendations(self.ratings, self.cfg.rating_threshold_wbf)\n",
    "        #     grp.evaluate_wbf()\n",
    "\n",
    "#     def run_all_methods(self, groups):\n",
    "#         if (groups is None):\n",
    "#             groups = self.groups\n",
    "#         #PS: could call them without passing groups as we have already added groups to grouprec object\n",
    "#         self.af_runner(groups, Aggregators.weighted_average)\n",
    "#         self.bf_runner(groups, Aggregators.average_bf)\n",
    "#         self.wbf_runner(groups, Aggregators.average_bf)\n",
    "\n",
    "#         #evaluation\n",
    "#         self.evaluation()\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     #Workflow\n",
    "#     gr = GroupRec()\n",
    "#     #can, move this function also to config __init__, will decide later\n",
    "# #     gr.read_data()\n",
    "#     #factorize matrix\n",
    "#     gr.sgd_factorize()\n",
    "    \n",
    "#     #add groups or generate random groups of given size\n",
    "#     groups = []\n",
    "#     members = [475, 549, 775]\n",
    "#     candidate_items = Group.find_candidate_items(gr.ratings, members)\n",
    "#     if len(candidate_items) != 0:\n",
    "#         pass\n",
    "#         #groups = [Group(gr.cfg, members, candidate_items, gr.ratings)]\n",
    "    \n",
    "#     #OR generate groups programmatically\n",
    "#     #disjoint means none of the groups shares any common members     \n",
    "#     small_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 3, gr.cfg.small_grp_size, disjoint=True)\n",
    "#     medium_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 3, gr.cfg.medium_grp_size, disjoint=True)\n",
    "#     large_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 3, gr.cfg.large_grp_size, disjoint=True)\n",
    "    \n",
    "#     group_set = [small_groups, medium_groups, large_groups]\n",
    "#     group_type = ['small', 'medium', 'large']\n",
    "    \n",
    "#     for idx, groups in enumerate(group_set):\n",
    "#         if groups is []: continue;\n",
    "        \n",
    "#         #generated groups\n",
    "#         print '******* Running for ', group_type[idx], ' groups *************'\n",
    "#         print 'generated groups: '\n",
    "#         for group in groups:\n",
    "#             print(group.members)\n",
    "        \n",
    "#         gr.add_groups(groups)\n",
    "#         gr.run_all_methods(groups)\n",
    "#         gr.remove_groups(groups)    \n",
    "#         pass\n",
    "print 'GroupRec block completed!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import _GroupRec\n",
    "# class GroupRec :\n",
    "def run_all_methods(self, groups):\n",
    "    if (groups is None):\n",
    "        groups = self.groups\n",
    "    #PS: could call them without passing groups as we have already added groups to grouprec object\n",
    "    self.af_runner(groups, Aggregators.weighted_average)\n",
    "    self.bf_runner(groups, Aggregators.average_bf)\n",
    "    self.wbf_runner(groups, Aggregators.average_bf)\n",
    "\n",
    "    #evaluation\n",
    "    self.evaluation()\n",
    "GroupRec.run_all_methods = classmethod(run_all_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from  ./data/u1.base ...\n",
      "Reading testing data from  ./data/u1.test ...\n",
      "Doing matrix factorization...\n",
      "Iteration:  0\n",
      "training mse:  0.80400900094\n",
      "test mse:  1.06078665703\n",
      "******* Running for  small  groups *************\n",
      "generated groups: \n",
      "[15, 61, 831]\n",
      "[200, 531, 645]\n",
      "[73, 317, 386]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "GroupRec instance has no attribute 'run_all_methods'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e8b399d5f334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_all_methods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: GroupRec instance has no attribute 'run_all_methods'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Workflow\n",
    "    gr = GroupRec()\n",
    "    #can, move this function also to config __init__, will decide later\n",
    "#     gr.read_data()\n",
    "    #factorize matrix\n",
    "    gr.sgd_factorize()\n",
    "    \n",
    "    #add groups or generate random groups of given size\n",
    "    groups = []\n",
    "    members = [475, 549, 775]\n",
    "    candidate_items = Group.find_candidate_items(gr.ratings, members)\n",
    "    if len(candidate_items) != 0:\n",
    "        pass\n",
    "        #groups = [Group(gr.cfg, members, candidate_items, gr.ratings)]\n",
    "    \n",
    "    #OR generate groups programmatically\n",
    "    #disjoint means none of the groups shares any common members     \n",
    "    small_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 3, gr.cfg.small_grp_size, disjoint=True)\n",
    "    medium_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 3, gr.cfg.medium_grp_size, disjoint=True)\n",
    "    large_groups = Group.generate_groups(gr.cfg, gr.ratings, gr.test_ratings, gr.num_users, 3, gr.cfg.large_grp_size, disjoint=True)\n",
    "    \n",
    "    group_set = [small_groups, medium_groups, large_groups]\n",
    "    group_type = ['small', 'medium', 'large']\n",
    "    \n",
    "    for idx, groups in enumerate(group_set):\n",
    "        if groups is []: continue;\n",
    "        \n",
    "        #generated groups\n",
    "        print '******* Running for ', group_type[idx], ' groups *************'\n",
    "        print 'generated groups: '\n",
    "        for group in groups:\n",
    "            print(group.members)\n",
    "        \n",
    "        gr.add_groups(groups)\n",
    "        gr.run_all_methods(groups)\n",
    "        gr.remove_groups(groups)    \n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
