{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, members, candidate_items, ratings):\n",
    "        # member ids\n",
    "        self.members = sorted(members)\n",
    "        \n",
    "        # List of items that can be recommended.\n",
    "        # These should not have been watched by any member of group.\n",
    "        self.candidate_items = candidate_items\n",
    "\n",
    "        self.actual_recos = []\n",
    "        self.false_positive = []\n",
    "        \n",
    "        self.ratings_per_member = [np.size(ratings[member].nonzero()) for member in self.members]\n",
    "        \n",
    "        # AF\n",
    "        self.grp_factors_af = []\n",
    "        self.bias_af = 0\n",
    "        self.precision_af = 0\n",
    "        self.recall_af = 0\n",
    "        self.reco_list_af = [] \n",
    "        \n",
    "        # BF\n",
    "        self.grp_factors_bf = []\n",
    "        self.bias_bf = 0\n",
    "        self.precision_bf = 0\n",
    "        self.recall_bf = 0\n",
    "        self.reco_list_bf = []\n",
    "        \n",
    "        # WBF\n",
    "        self.grp_factors_wbf = []\n",
    "        self.bias_wbf = 0\n",
    "        self.precision_wbf = 0\n",
    "        self.recall_wbf = 0\n",
    "        self.weight_matrix_wbf = []\n",
    "        self.reco_list_wbf = []\n",
    "    \n",
    "    # Verifies that given list of members can form a group w.r.t given data\n",
    "    # ensure that there is at least 1 movie in training data that hasn't been\n",
    "    # watched by any member of the group. Only these can be recommended.\n",
    "    # call this method before calling group constructor.\n",
    "    @staticmethod\n",
    "    def find_candidate_items(ratings, members):\n",
    "        if len(members) == 0:\n",
    "            return []\n",
    "        \n",
    "        unwatched_items = np.argwhere(ratings[members[0]] == 0)\n",
    "        for member in members:\n",
    "            cur_unwatched = np.argwhere(ratings[member] == 0)\n",
    "            unwatched_items = np.intersect1d(unwatched_items, cur_unwatched)\n",
    "        \n",
    "        return unwatched_items\n",
    "    \n",
    "    # generate groups of given size\n",
    "    @staticmethod\n",
    "    def generate_groups(ratings, test_ratings, num_users, count, size, disjoint=True):\n",
    "        avbl_users = [i for i in range(num_users)]\n",
    "        groups = []\n",
    "        testable_threshold = 50\n",
    "        \n",
    "        iter_idx = 0\n",
    "        while iter_idx in range(count):\n",
    "            group_members = np.random.choice(avbl_users, size=size, replace=False)\n",
    "            candidate_items = Group.find_candidate_items(ratings, group_members)\n",
    "            non_eval_items = Group.non_testable_items(group_members, test_ratings)\n",
    "            testable_items = np.setdiff1d(candidate_items, non_eval_items)\n",
    "            \n",
    "            if len(candidate_items) != 0 and len(testable_items) >= testable_threshold:\n",
    "                groups += [Group(group_members, candidate_items, ratings)]\n",
    "\n",
    "                if disjoint:\n",
    "                    avbl_users = np.setdiff1d(avbl_users, group_members)\n",
    "                iter_idx += 1\n",
    "                \n",
    "        return groups\n",
    "    \n",
    "    @staticmethod\n",
    "    def non_testable_items(members, ratings): \n",
    "        non_eval_items = np.argwhere(ratings[members[0]] == 0)\n",
    "        for member in members:\n",
    "            cur_non_eval_items = np.argwhere(ratings[member] == 0)\n",
    "            non_eval_items = np.intersect1d(non_eval_items, cur_non_eval_items)\n",
    "        return non_eval_items\n",
    "    \n",
    "    def generate_actual_recommendations(self, ratings, threshold, is_debug=False):\n",
    "        non_eval_items = Group.non_testable_items(self.members, ratings)\n",
    "            \n",
    "        items = np.argwhere(np.logical_or(ratings[self.members[0]] >= threshold, ratings[self.members[0]] == 0)).flatten()\n",
    "        fp = np.argwhere(np.logical_and(ratings[self.members[0]] > 0, ratings[self.members[0]] < threshold)).flatten()\n",
    "        for member in self.members:\n",
    "            cur_items = np.argwhere(np.logical_or(ratings[member] >= threshold, ratings[member] == 0)).flatten()\n",
    "            fp = np.union1d(fp, np.argwhere(np.logical_and(ratings[member] > 0, ratings[member] < threshold)).flatten())\n",
    "            items = np.intersect1d(items, cur_items)\n",
    "        \n",
    "        items = np.setdiff1d(items, non_eval_items)\n",
    "\n",
    "        self.actual_recos = items\n",
    "        self.false_positive = fp\n",
    "        if is_debug:\n",
    "            print '\\nT: ', self.actual_recos.size, ' F: ', self.false_positive.size\n",
    "\n",
    "    def evaluate_af(self, is_debug=False):\n",
    "        tp = float(np.intersect1d(self.actual_recos, self.reco_list_af).size)\n",
    "        fp = float(np.intersect1d(self.false_positive, self.reco_list_af).size)\n",
    "        \n",
    "        try:\n",
    "            self.precision_af = tp / (tp + fp)\n",
    "        except ZeroDivisionError:\n",
    "            self.precision_af = np.NaN\n",
    "\n",
    "        try:\n",
    "            self.recall_af = tp / self.actual_recos.size\n",
    "        except ZeroDivisionError:\n",
    "            self.recall_af = np.NaN\n",
    "\n",
    "        if is_debug:\n",
    "            print 'tp: ', tp\n",
    "            print 'fp: ', fp\n",
    "            print 'precision_af: ', self.precision_af\n",
    "            print 'recall_af: ', self.recall_af\n",
    "\n",
    "        return self.precision_af, self.recall_af, tp, fp\n",
    "\n",
    "    def evaluate_bf(self, is_debug=False):\n",
    "        tp = float(np.intersect1d(self.actual_recos, self.reco_list_bf).size)\n",
    "        fp = float(np.intersect1d(self.false_positive, self.reco_list_bf).size)\n",
    "\n",
    "        try:\n",
    "            self.precision_bf = tp / (tp + fp)\n",
    "        except ZeroDivisionError:\n",
    "            self.precision_bf = np.NaN\n",
    "\n",
    "        try:\n",
    "            self.recall_bf = tp / self.actual_recos.size\n",
    "        except ZeroDivisionError:\n",
    "            self.recall_bf = np.NaN\n",
    "\n",
    "        if is_debug:\n",
    "            print 'tp: ', tp\n",
    "            print 'fp: ', fp\n",
    "            print 'precision_bf: ', self.precision_bf\n",
    "            print 'recall_bf: ', self.recall_bf\n",
    "\n",
    "        return self.precision_bf, self.recall_bf, tp, fp\n",
    "\n",
    "    def evaluate_wbf(self, is_debug=False):\n",
    "        tp = float(np.intersect1d(self.actual_recos, self.reco_list_wbf).size)\n",
    "        fp = float(np.intersect1d(self.false_positive, self.reco_list_wbf).size)\n",
    "\n",
    "        try:\n",
    "            self.precision_wbf = tp / (tp + fp)\n",
    "        except ZeroDivisionError:\n",
    "            self.precision_wbf = np.NaN\n",
    "\n",
    "        try:\n",
    "            self.recall_wbf = tp / self.actual_recos.size\n",
    "        except ZeroDivisionError:\n",
    "            self.recall_wbf = np.NaN\n",
    "\n",
    "        if is_debug:\n",
    "            print 'tp: ', tp\n",
    "            print 'fp: ', fp\n",
    "            print 'precision_bf: ', self.precision_wbf\n",
    "            print 'recall_bf: ', self.recall_wbf\n",
    "\n",
    "        return self.precision_wbf, self.recall_wbf, tp, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Aggregators:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def average(arr):\n",
    "        return np.average(arr, axis = 0, weights = None)\n",
    "\n",
    "    @staticmethod\n",
    "    def average_bf(arr):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            arr[arr == 0] = np.nan\n",
    "            return np.nanmean(arr, axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def weighted_average(arr, weights):\n",
    "        return np.average(arr, axis = 0, weights = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Aggregators import Aggregators\n",
    "from Group import Group\n",
    "from Config import Config\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as ps\n",
    "\n",
    "\n",
    "# overflow warnings should be raised as errors\n",
    "np.seterr(over='raise')\n",
    "\n",
    "\n",
    "class GroupRec:\n",
    "    def __init__(self):\n",
    "        self.cfg = Config(r\"./config.conf\")\n",
    "        \n",
    "        # training and testing matrices\n",
    "        self.ratings = None\n",
    "        self.test_ratings = None\n",
    "\n",
    "        self.groups = []\n",
    "        \n",
    "        # read data into above matrices\n",
    "        self.read_data()\n",
    "        \n",
    "        self.num_users = self.ratings.shape[0]\n",
    "        self.num_items = self.ratings.shape[1]\n",
    "        \n",
    "        # predicted ratings matrix based on factors.\n",
    "        self.predictions = np.zeros((self.num_users, self.num_items))\n",
    "        \n",
    "        # output after svd factorization\n",
    "        # initialize all unknowns with random values from -1 to 1\n",
    "        self.user_factors = np.random.uniform(-1, 1, (self.ratings.shape[0], self.cfg.num_factors))\n",
    "        self.item_factors = np.random.uniform(-1, 1, (self.ratings.shape[1], self.cfg.num_factors))\n",
    "\n",
    "        self.user_biases = np.zeros(self.num_users)\n",
    "        self.item_biases = np.zeros(self.num_items)\n",
    "        \n",
    "        # global mean of ratings a.k.a mu\n",
    "        self.ratings_global_mean = 0\n",
    "\n",
    "    # read training and testing data into matrices\n",
    "    def read_data(self):\n",
    "        column_headers = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "\n",
    "        print 'Reading training data from ', self.cfg.training_file, '...'\n",
    "        training_data = ps.read_csv(self.cfg.training_file, sep='\\t', names=column_headers)\n",
    "\n",
    "        print 'Reading testing data from ', self.cfg.testing_file, '...'\n",
    "        testing_data = ps.read_csv(self.cfg.testing_file, sep='\\t', names=column_headers)\n",
    "\n",
    "        num_users = max(training_data.user_id.unique())\n",
    "        num_items = max(training_data.item_id.unique())\n",
    "\n",
    "        self.ratings = np.zeros((num_users, num_items))\n",
    "        self.test_ratings = np.zeros((num_users, num_items))\n",
    "\n",
    "        for row in training_data.itertuples(index=False):\n",
    "            self.ratings[row.user_id - 1, row.item_id - 1] = row.rating\n",
    "\n",
    "        for row in testing_data.itertuples(index=False):\n",
    "            self.test_ratings[row.user_id - 1, row.item_id - 1] = row.rating\n",
    "\n",
    "    # add list of groups\n",
    "    def add_groups(self, groups):\n",
    "        self.groups = groups\n",
    "    \n",
    "    # remove groups\n",
    "    def remove_groups(self, groups):\n",
    "        self.groups = []\n",
    "    \n",
    "    def predict_user_rating(self, user, item):\n",
    "        prediction = self.ratings_global_mean + self.user_biases[user] + self.item_biases[item]\n",
    "        prediction += self.user_factors[user, :].dot(self.item_factors[item, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    def predict_group_rating(self, grp, item, method):\n",
    "        bias_grp = 0\n",
    "        factors = np.nan\n",
    "        if method == 'af':\n",
    "            factors = grp.grp_factors_af; bias_grp = grp.bias_af\n",
    "        elif method == 'bf':\n",
    "            factors = grp.grp_factors_bf; bias_grp = grp.bias_bf\n",
    "        elif method == 'wbf':\n",
    "            factors = grp.grp_factors_wbf; bias_grp = grp.bias_wbf\n",
    "        \n",
    "        return self.ratings_global_mean + bias_grp + self.item_biases[item] \\\n",
    "                                        + np.dot(factors.T, self.item_factors[item])\n",
    "\n",
    "    def predict_all_ratings(self):\n",
    "        for user in range(self.num_users):\n",
    "            for item in range(self.num_items):\n",
    "                self.predictions[user, item] = self.predict_user_rating(user, item)\n",
    "        \n",
    "    # matrix factorization code\n",
    "    def sgd_factorize(self):\n",
    "        regularization = self.cfg.lambda_mf\n",
    "        learning_rate = self.cfg.learning_rate_mf\n",
    "\n",
    "        self.ratings_global_mean = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "\n",
    "        # solve for these for matrix ratings\n",
    "        ratings_row, ratings_col = self.ratings.nonzero()\n",
    "        num_ratings = len(ratings_row)\n",
    "        \n",
    "        print 'Doing matrix factorization...'\n",
    "        try:\n",
    "            for iter in range(self.cfg.max_iterations_mf):\n",
    "                print 'Iteration: ', iter\n",
    "                rating_indices = np.arange(num_ratings)\n",
    "                np.random.shuffle(rating_indices)\n",
    "                \n",
    "                for idx in rating_indices:\n",
    "                    user = ratings_row[idx]\n",
    "                    item = ratings_col[idx]\n",
    "\n",
    "                    pred = self.predict_user_rating(user, item)\n",
    "                    error = self.ratings[user][item] - pred\n",
    "                    \n",
    "                    self.user_factors[user] += learning_rate * ((error * self.item_factors[item])\n",
    "                                                    - (regularization * self.user_factors[user]))\n",
    "                    self.item_factors[item] += learning_rate * ((error * self.user_factors[user])\n",
    "                                                    - (regularization * self.item_factors[item]))\n",
    "                    \n",
    "                    self.user_biases[user] += learning_rate * (error - regularization * self.user_biases[user])\n",
    "                    self.item_biases[item] += learning_rate * (error - regularization * self.item_biases[item])\n",
    "            \n",
    "                if self.cfg.is_debug:\n",
    "                    self.sgd_mse()\n",
    "            \n",
    "        except FloatingPointError:\n",
    "            print 'Floating point Error: '\n",
    "\n",
    "    def sgd_mse(self):\n",
    "        self.predict_all_ratings()\n",
    "        predicted_training_ratings = self.predictions[self.ratings.nonzero()].flatten()\n",
    "        actual_training_ratings = self.ratings[self.ratings.nonzero()].flatten()\n",
    "        \n",
    "        predicted_test_ratings = self.predictions[self.test_ratings.nonzero()].flatten()\n",
    "        actual_test_ratings = self.test_ratings[self.test_ratings.nonzero()].flatten()\n",
    "    \n",
    "        training_mse = mean_squared_error(predicted_training_ratings, actual_training_ratings)\n",
    "        print 'training mse: ', training_mse\n",
    "\n",
    "        test_mse = mean_squared_error(predicted_test_ratings, actual_test_ratings)\n",
    "        print 'test mse: ', test_mse\n",
    "\n",
    "    # AF Method\n",
    "    def af_runner(self, grps=None, aggregator=Aggregators.average):\n",
    "        if grps is None:\n",
    "            grps = self.groups\n",
    "        \n",
    "        # calculate factors\n",
    "        for grp in grps:\n",
    "            member_factors = self.user_factors[grp.members, :]\n",
    "            member_biases = self.user_biases[grp.members]\n",
    "        \n",
    "            # aggregate the factors\n",
    "            if aggregator == Aggregators.average:\n",
    "                grp.grp_factors_af = aggregator(member_factors)\n",
    "                grp.bias_af = aggregator(member_biases)\n",
    "            elif aggregator == Aggregators.weighted_average:\n",
    "                grp.grp_factors_af = aggregator(member_factors, weights=grp.ratings_per_member)\n",
    "                grp.bias_af = aggregator(member_biases, weights=grp.ratings_per_member)\n",
    "\n",
    "            self.make_recommendations_for_af(grp)\n",
    "\n",
    "    def make_recommendations_for_af(self, grp):\n",
    "        # predict ratings for all candidate items\n",
    "        group_candidate_ratings = {}\n",
    "        for idx, item in enumerate(grp.candidate_items):\n",
    "            cur_rating = self.predict_group_rating(grp, item, 'af')\n",
    "            if cur_rating > self.cfg.rating_threshold_af:\n",
    "                group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "        # sort and filter to keep top 'num_recos_af' recommendations\n",
    "        group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[:self.cfg.num_recos_af]\n",
    "        grp.reco_list_af = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "\n",
    "    def make_recommendations_for_bf(self, grp):\n",
    "        # predict ratings for all candidate items\n",
    "        group_candidate_ratings = {}\n",
    "        for idx, item in enumerate(grp.candidate_items):\n",
    "            cur_rating = self.predict_group_rating(grp, item, 'bf')\n",
    "            if cur_rating > self.cfg.rating_threshold_bf:\n",
    "                group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "        # sort and filter to keep top 'num_recos_bf' recommendations\n",
    "        group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[:self.cfg.num_recos_bf]\n",
    "        grp.reco_list_bf = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "\n",
    "    def make_recommendations_for_wbf(self, grp):\n",
    "        # predict ratings for all candidate items\n",
    "        group_candidate_ratings = {}\n",
    "        for idx, item in enumerate(grp.candidate_items):\n",
    "            cur_rating = self.predict_group_rating(grp, item, 'wbf')\n",
    "            if cur_rating > self.cfg.rating_threshold_wbf:\n",
    "                group_candidate_ratings[item] = cur_rating\n",
    "\n",
    "        # sort and filter to keep top 'num_recos_wbf' recommendations\n",
    "        group_candidate_ratings = sorted(group_candidate_ratings.items(), key=lambda x: x[1], reverse=True)[:self.cfg.num_recos_wbf]\n",
    "        grp.reco_list_wbf = np.array([rating_tuple[0] for rating_tuple in group_candidate_ratings])\n",
    "\n",
    "    def get_weight_matrix(self, grp, watched_items):\n",
    "        wt = []\n",
    "        for item in watched_items:\n",
    "            rated = np.argwhere(self.ratings[:, item] != 0)  # list of users who have rated this movie\n",
    "            watched = np.intersect1d(rated, grp)  # list of group members who have watched this movie\n",
    "            std_dev = np.std(filter(lambda a: a != 0, self.ratings[:, item]))  # std deviation for the rating of the item\n",
    "            wt += [len(watched) / float(len(grp.members)) * 1 / (1 + std_dev)]  # list containing diagonal elements\n",
    "        W = np.diag(wt)  # diagonal weight matrix\n",
    "        return W\n",
    "\n",
    "    # BF/WBF Method\n",
    "    def bf_runner(self, grps=None, aggregator=Aggregators.average_bf, is_wbf=False):\n",
    "        # aggregate user ratings into virtual group\n",
    "        # calculate factors of group\n",
    "        lamb = self.cfg.lambda_mf\n",
    "        for grp in grps:\n",
    "            all_movies = np.arange(len(self.ratings.T))\n",
    "            watched_items = sorted(list(set(all_movies) - set(grp.candidate_items)))\n",
    "\n",
    "            group_rating = self.ratings[grp.members, :]\n",
    "            agg_rating = aggregator(group_rating)\n",
    "            s_g = []\n",
    "            for j in watched_items:\n",
    "                s_g.append(agg_rating[j] - self.ratings_global_mean - self.item_biases[j])\n",
    "\n",
    "            # creating matrix A : contains rows of [item_factors of items in watched_list + '1' vector]\n",
    "            A = np.zeros((0, self.cfg.num_factors))  # 3 is the number of features here = K\n",
    "\n",
    "            for item in watched_items:\n",
    "                A = np.vstack([A, self.item_factors[item]])\n",
    "            v = np.ones((len(watched_items), 1))\n",
    "            A = np.c_[A, v]\n",
    "\n",
    "            if is_wbf:\n",
    "                W = self.get_weight_matrix(grp, watched_items)\n",
    "                factor_n_bias = np.dot(np.linalg.inv(np.dot(np.dot(A.T, W),A) + lamb * np.identity(self.cfg.num_factors + 1)), np.dot(np.dot(A.T, W), s_g))\n",
    "                grp.grp_factors_wbf = factor_n_bias[:-1]\n",
    "                grp.bias_wbf = factor_n_bias[-1]\n",
    "                self.make_recommendations_for_wbf(grp)\n",
    "            else:\n",
    "                factor_n_bias = np.dot(np.linalg.inv(np.dot(A.T, A) + lamb * np.identity(self.cfg.num_factors + 1)), np.dot(A.T, s_g))\n",
    "                grp.grp_factors_bf = factor_n_bias[:-1]\n",
    "                grp.bias_bf = factor_n_bias[-1]\n",
    "                self.make_recommendations_for_bf(grp)\n",
    "\n",
    "    def evaluation(self):\n",
    "        # For AF\n",
    "        af_precision_list = []\n",
    "        af_recall_list = []\n",
    "        print \"\\n#########-------For AF-------#########\"\n",
    "        for grp in self.groups:\n",
    "            grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_af, self.cfg.is_debug)\n",
    "            (precision, recall, tp, fp) = grp.evaluate_af(self.cfg.is_debug)\n",
    "            af_precision_list.append(precision)\n",
    "            af_recall_list.append(recall)\n",
    "        \n",
    "        af_mean_precision = np.nanmean(np.array(af_precision_list))\n",
    "        af_mean_recall = np.nanmean(np.array(af_recall_list))\n",
    "        print '\\nAF method: mean precision: ', af_mean_precision\n",
    "        print 'AF method: mean recall: ', af_mean_recall\n",
    "\n",
    "        # For BF\n",
    "        bf_precision_list = []\n",
    "        bf_recall_list = []\n",
    "        print \"\\n#########-------For BF-------#########\"\n",
    "        for grp in self.groups:\n",
    "            grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_bf, self.cfg.is_debug)\n",
    "            (precision, recall, tp, fp) = grp.evaluate_bf(self.cfg.is_debug)\n",
    "            bf_precision_list.append(precision)\n",
    "            bf_recall_list.append(recall)\n",
    "\n",
    "        bf_mean_precision = np.nanmean(np.array(bf_precision_list))\n",
    "        bf_mean_recall = np.nanmean(np.array(bf_recall_list))\n",
    "        print '\\nBF method: mean precision: ', bf_mean_precision\n",
    "        print 'BF method: mean recall: ', bf_mean_recall\n",
    "\n",
    "        # For WBF\n",
    "        wbf_precision_list = []\n",
    "        wbf_recall_list = []\n",
    "        print \"\\n#########-------For WBF-------#########\"\n",
    "        for grp in self.groups:\n",
    "            grp.generate_actual_recommendations(self.test_ratings, self.cfg.rating_threshold_wbf, self.cfg.is_debug)\n",
    "            (precision, recall, tp, fp) = grp.evaluate_wbf(self.cfg.is_debug)\n",
    "            wbf_precision_list.append(precision)\n",
    "            wbf_recall_list.append(recall)\n",
    "\n",
    "        wbf_mean_precision = np.nanmean(np.array(wbf_precision_list))\n",
    "        wbf_mean_recall = np.nanmean(np.array(wbf_recall_list))\n",
    "        print '\\nWBF method: mean precision: ', wbf_mean_precision\n",
    "        print 'WBF method: mean recall: ', wbf_mean_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_all_methods(self, grps):\n",
    "    if grps is None:\n",
    "        grps = self.groups\n",
    "\n",
    "    self.af_runner(grps, Aggregators.weighted_average)\n",
    "    self.bf_runner(grps, Aggregators.average_bf)\n",
    "    self.bf_runner(grps, Aggregators.average_bf, is_wbf=True)  # For WBF\n",
    "\n",
    "    # evaluation\n",
    "    self.evaluation()\n",
    "\n",
    "GroupRec.run_all_methods = run_all_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data from  ./data/u1.base ...\n",
      "Reading testing data from  ./data/u1.test ...\n",
      "Doing matrix factorization...\n",
      "Iteration:  0\n",
      "\n",
      "******* Running for  small  groups *************\n",
      "generated groups (only 5 are getting printed here): \n",
      "[82, 93, 371]\n",
      "[206, 288, 529]\n",
      "[57, 145, 267]\n",
      "[63, 345, 670]\n",
      "[322, 325, 543]\n",
      "\n",
      "#########-------For AF-------#########\n",
      "\n",
      "AF method: mean precision:  0.828251881561\n",
      "AF method: mean recall:  0.0833815853777\n",
      "\n",
      "#########-------For BF-------#########\n",
      "\n",
      "BF method: mean precision:  0.740671332636\n",
      "BF method: mean recall:  0.0409910891095\n",
      "\n",
      "#########-------For WBF-------#########\n",
      "\n",
      "WBF method: mean precision:  0.798686223968\n",
      "WBF method: mean recall:  0.141507108783\n",
      "\n",
      "******* Running for  medium  groups *************\n",
      "generated groups (only 5 are getting printed here): \n",
      "[107, 303, 306, 679, 708]\n",
      "[81, 176, 350, 468, 631]\n",
      "[68, 258, 263, 726, 766]\n",
      "[84, 413, 527, 818, 880]\n",
      "[145, 196, 294, 385, 622]\n",
      "\n",
      "#########-------For AF-------#########\n",
      "\n",
      "AF method: mean precision:  0.804323425852\n",
      "AF method: mean recall:  0.061140671378\n",
      "\n",
      "#########-------For BF-------#########\n",
      "\n",
      "BF method: mean precision:  0.678826222797\n",
      "BF method: mean recall:  0.0401079671431\n",
      "\n",
      "#########-------For WBF-------#########\n",
      "\n",
      "WBF method: mean precision:  0.773706444019\n",
      "WBF method: mean recall:  0.0953574160117\n",
      "\n",
      "******* Running for  large  groups *************\n",
      "generated groups (only 5 are getting printed here): \n",
      "[10, 76, 91, 188, 199, 354, 626, 689, 821, 853]\n",
      "[108, 296, 373, 379, 387, 405, 628, 667, 795, 869]\n",
      "[48, 161, 265, 290, 445, 562, 661, 789, 891, 894]\n",
      "[1, 48, 49, 72, 149, 184, 468, 516, 564, 612]\n",
      "[82, 172, 218, 282, 417, 532, 774, 811, 858, 906]\n",
      "\n",
      "#########-------For AF-------#########\n",
      "\n",
      "AF method: mean precision:  0.784868489336\n",
      "AF method: mean recall:  0.0527424684595\n",
      "\n",
      "#########-------For BF-------#########\n",
      "\n",
      "BF method: mean precision:  0.744484277297\n",
      "BF method: mean recall:  0.0327271032306\n",
      "\n",
      "#########-------For WBF-------#########\n",
      "\n",
      "WBF method: mean precision:  0.804741933403\n",
      "WBF method: mean recall:  0.0626019653408\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gr = GroupRec()\n",
    "\n",
    "    # factorize matrix\n",
    "    gr.sgd_factorize()\n",
    "    \n",
    "    # add groups or generate random groups of given size\n",
    "    groups = []\n",
    "\n",
    "    # members = [475, 549, 775]\n",
    "    # candidate_items = Group.find_candidate_items(gr.ratings, members)\n",
    "    # if len(candidate_items) != 0:\n",
    "    #   groups = [Group(gr.cfg, members, candidate_items, gr.ratings)]\n",
    "\n",
    "    # disjoint means none of the groups shares any common members\n",
    "    small_groups = Group.generate_groups(gr.ratings, gr.test_ratings, gr.num_users, gr.cfg.no_of_small_grps, gr.cfg.small_grp_size, disjoint=False)\n",
    "    medium_groups = Group.generate_groups(gr.ratings, gr.test_ratings, gr.num_users, gr.cfg.no_of_medium_grps, gr.cfg.medium_grp_size, disjoint=False)\n",
    "    large_groups = Group.generate_groups(gr.ratings, gr.test_ratings, gr.num_users, gr.cfg.no_of_large_grps, gr.cfg.large_grp_size, disjoint=False)\n",
    "    \n",
    "    group_set = [small_groups, medium_groups, large_groups]\n",
    "    group_type = ['small', 'medium', 'large']\n",
    "    \n",
    "    for idx, groups in enumerate(group_set):\n",
    "        if groups is []:\n",
    "            continue\n",
    "        \n",
    "        # generated groups\n",
    "        n = len(groups) if gr.cfg.is_debug else 5\n",
    "        print '\\n******* Running for ', group_type[idx], ' groups *************'\n",
    "        print 'generated groups (only %d are getting printed here): ' % n\n",
    "        for group in groups[:n]:\n",
    "            print(group.members)\n",
    "        \n",
    "        gr.add_groups(groups)\n",
    "        gr.run_all_methods(groups)\n",
    "        gr.remove_groups(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
